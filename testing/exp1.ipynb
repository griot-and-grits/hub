{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing transcriptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spin up ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ollama run llama3.2:1b --keepalive 60m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "okay so um we were talkin about that time granddaddy slipped behind the stove yeah that was in the s\n"
     ]
    }
   ],
   "source": [
    "def get_transcript(file_name: str):\n",
    "    return open(file_name, \"r\").read()\n",
    "\n",
    "\n",
    "transcript = get_transcript(\"data/mcclendon_tapes.txt\")\n",
    "print(transcript[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensure LLS is active + the model we are using to test exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET http://localhost:8321/v1/models \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "from llama_stack_client import LlamaStackClient\n",
    "\n",
    "model = \"llama3.2:3b\"\n",
    "client = LlamaStackClient(\n",
    "    base_url=\"http://localhost:8321\"\n",
    ")\n",
    "\n",
    "models = client.models.list()\n",
    "assert model in [m.identifier for m in models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://localhost:8321/v1/inference/chat-completion \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ChatCompletionResponse(completion_message=CompletionMessage(content=\"This conversation has just begun. There is no transcript to share yet. What would you like to talk about or ask? I can summarize our conversation at the end if you'd like.\", role='assistant', stop_reason='end_of_turn', tool_calls=[]), logprobs=None, metrics=[Metric(metric='prompt_tokens', value=15.0, unit=None), Metric(metric='completion_tokens', value=47.0, unit=None), Metric(metric='total_tokens', value=62.0, unit=None)])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.inference.chat_completion(model_id=model, messages=[{\"role\": \"user\", \"content\": \"What is the transcript?\"}])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine GPU to use, if not default to CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def determine_torch_device():\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device(\"cuda\")\n",
    "    elif torch.backends.mps.is_available():\n",
    "        return torch.device(\"mps\")\n",
    "    else:\n",
    "        return torch.device(\"cpu\")\n",
    "\n",
    "device = determine_torch_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:speechbrain.utils.checkpoints:Registered checkpoint save hook for _speechbrain_save\n",
      "DEBUG:speechbrain.utils.checkpoints:Registered checkpoint load hook for _speechbrain_load\n",
      "DEBUG:speechbrain.utils.checkpoints:Registered checkpoint save hook for save\n",
      "DEBUG:speechbrain.utils.checkpoints:Registered checkpoint load hook for load\n",
      "INFO:speechbrain.utils.quirks:Applied quirks (see `speechbrain.utils.quirks`): [allow_tf32, disable_jit_profiling]\n",
      "INFO:speechbrain.utils.quirks:Excluded quirks specified by the `SB_DISABLE_QUIRKS` environment (comma-separated list): []\n",
      "DEBUG:speechbrain.utils.checkpoints:Registered checkpoint save hook for _save\n",
      "DEBUG:speechbrain.utils.checkpoints:Registered checkpoint load hook for _recover\n",
      "INFO:pytorch_lightning.utilities.migration.utils:Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.5.1.post0. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../../../.cache/torch/pyannote/models--pyannote--segmentation/snapshots/c4c8ceafcbb3a7a280c2d357aee9fbc9b0be7f9b/pytorch_model.bin`\n",
      "INFO:speechbrain.utils.fetching:Fetch hyperparams.yaml: Using symlink found at '/Users/sglinton/.cache/torch/pyannote/speechbrain/hyperparams.yaml'\n",
      "INFO:speechbrain.utils.fetching:Fetch custom.py: Fetching from HuggingFace Hub 'speechbrain/spkrec-ecapa-voxceleb' if not cached\n",
      "DEBUG:speechbrain.utils.checkpoints:Registered checkpoint save hook for _save\n",
      "DEBUG:speechbrain.utils.checkpoints:Registered checkpoint load hook for _load\n",
      "DEBUG:speechbrain.utils.checkpoints:Registered parameter transfer hook for _load\n",
      "/Users/sglinton/dev/hub/.venv/lib/python3.12/site-packages/speechbrain/utils/autocast.py:188: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  wrapped_fwd = torch.cuda.amp.custom_fwd(fwd, cast_inputs=cast_inputs)\n",
      "DEBUG:speechbrain.utils.checkpoints:Registered checkpoint save hook for save\n",
      "DEBUG:speechbrain.utils.checkpoints:Registered checkpoint load hook for load_if_possible\n",
      "DEBUG:speechbrain.utils.parameter_transfer:Collecting files (or symlinks) for pretraining in /Users/sglinton/.cache/torch/pyannote/speechbrain.\n",
      "INFO:speechbrain.utils.fetching:Fetch embedding_model.ckpt: Using symlink found at '/Users/sglinton/.cache/torch/pyannote/speechbrain/embedding_model.ckpt'\n",
      "DEBUG:speechbrain.utils.parameter_transfer:Set local path in self.paths[\"embedding_model\"] = /Users/sglinton/.cache/torch/pyannote/speechbrain/embedding_model.ckpt\n",
      "INFO:speechbrain.utils.fetching:Fetch mean_var_norm_emb.ckpt: Using symlink found at '/Users/sglinton/.cache/torch/pyannote/speechbrain/mean_var_norm_emb.ckpt'\n",
      "DEBUG:speechbrain.utils.parameter_transfer:Set local path in self.paths[\"mean_var_norm_emb\"] = /Users/sglinton/.cache/torch/pyannote/speechbrain/mean_var_norm_emb.ckpt\n",
      "INFO:speechbrain.utils.fetching:Fetch classifier.ckpt: Using symlink found at '/Users/sglinton/.cache/torch/pyannote/speechbrain/classifier.ckpt'\n",
      "DEBUG:speechbrain.utils.parameter_transfer:Set local path in self.paths[\"classifier\"] = /Users/sglinton/.cache/torch/pyannote/speechbrain/classifier.ckpt\n",
      "INFO:speechbrain.utils.fetching:Fetch label_encoder.txt: Using symlink found at '/Users/sglinton/.cache/torch/pyannote/speechbrain/label_encoder.ckpt'\n",
      "DEBUG:speechbrain.utils.parameter_transfer:Set local path in self.paths[\"label_encoder\"] = /Users/sglinton/.cache/torch/pyannote/speechbrain/label_encoder.ckpt\n",
      "INFO:speechbrain.utils.parameter_transfer:Loading pretrained files for: embedding_model, mean_var_norm_emb, classifier, label_encoder\n",
      "DEBUG:speechbrain.utils.parameter_transfer:Redirecting (loading from local path): embedding_model -> /Users/sglinton/.cache/torch/pyannote/speechbrain/embedding_model.ckpt\n",
      "DEBUG:speechbrain.utils.parameter_transfer:Redirecting (loading from local path): mean_var_norm_emb -> /Users/sglinton/.cache/torch/pyannote/speechbrain/mean_var_norm_emb.ckpt\n",
      "DEBUG:speechbrain.utils.parameter_transfer:Redirecting (loading from local path): classifier -> /Users/sglinton/.cache/torch/pyannote/speechbrain/classifier.ckpt\n",
      "DEBUG:speechbrain.utils.parameter_transfer:Redirecting (loading from local path): label_encoder -> /Users/sglinton/.cache/torch/pyannote/speechbrain/label_encoder.ckpt\n",
      "DEBUG:speechbrain.dataio.encoder:Loaded categorical encoding from /Users/sglinton/.cache/torch/pyannote/speechbrain/label_encoder.ckpt\n",
      "INFO:speechbrain.utils.fetching:Fetch hyperparams.yaml: Using symlink found at '/Users/sglinton/.cache/torch/pyannote/speechbrain/hyperparams.yaml'\n",
      "INFO:speechbrain.utils.fetching:Fetch custom.py: Fetching from HuggingFace Hub 'speechbrain/spkrec-ecapa-voxceleb' if not cached\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.3.2. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.7.1. Bad things might happen unless you revert torch to 1.x.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:speechbrain.utils.parameter_transfer:Collecting files (or symlinks) for pretraining in /Users/sglinton/.cache/torch/pyannote/speechbrain.\n",
      "INFO:speechbrain.utils.fetching:Fetch embedding_model.ckpt: Using symlink found at '/Users/sglinton/.cache/torch/pyannote/speechbrain/embedding_model.ckpt'\n",
      "DEBUG:speechbrain.utils.parameter_transfer:Set local path in self.paths[\"embedding_model\"] = /Users/sglinton/.cache/torch/pyannote/speechbrain/embedding_model.ckpt\n",
      "INFO:speechbrain.utils.fetching:Fetch mean_var_norm_emb.ckpt: Using symlink found at '/Users/sglinton/.cache/torch/pyannote/speechbrain/mean_var_norm_emb.ckpt'\n",
      "DEBUG:speechbrain.utils.parameter_transfer:Set local path in self.paths[\"mean_var_norm_emb\"] = /Users/sglinton/.cache/torch/pyannote/speechbrain/mean_var_norm_emb.ckpt\n",
      "INFO:speechbrain.utils.fetching:Fetch classifier.ckpt: Using symlink found at '/Users/sglinton/.cache/torch/pyannote/speechbrain/classifier.ckpt'\n",
      "DEBUG:speechbrain.utils.parameter_transfer:Set local path in self.paths[\"classifier\"] = /Users/sglinton/.cache/torch/pyannote/speechbrain/classifier.ckpt\n",
      "INFO:speechbrain.utils.fetching:Fetch label_encoder.txt: Using symlink found at '/Users/sglinton/.cache/torch/pyannote/speechbrain/label_encoder.ckpt'\n",
      "DEBUG:speechbrain.utils.parameter_transfer:Set local path in self.paths[\"label_encoder\"] = /Users/sglinton/.cache/torch/pyannote/speechbrain/label_encoder.ckpt\n",
      "INFO:speechbrain.utils.parameter_transfer:Loading pretrained files for: embedding_model, mean_var_norm_emb, classifier, label_encoder\n",
      "DEBUG:speechbrain.utils.parameter_transfer:Redirecting (loading from local path): embedding_model -> /Users/sglinton/.cache/torch/pyannote/speechbrain/embedding_model.ckpt\n",
      "DEBUG:speechbrain.utils.parameter_transfer:Redirecting (loading from local path): mean_var_norm_emb -> /Users/sglinton/.cache/torch/pyannote/speechbrain/mean_var_norm_emb.ckpt\n",
      "DEBUG:speechbrain.utils.parameter_transfer:Redirecting (loading from local path): classifier -> /Users/sglinton/.cache/torch/pyannote/speechbrain/classifier.ckpt\n",
      "DEBUG:speechbrain.utils.parameter_transfer:Redirecting (loading from local path): label_encoder -> /Users/sglinton/.cache/torch/pyannote/speechbrain/label_encoder.ckpt\n",
      "DEBUG:speechbrain.dataio.encoder:Loaded categorical encoding from /Users/sglinton/.cache/torch/pyannote/speechbrain/label_encoder.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 00:00:00.030 -->  00:00:04.367] A SPEAKER_00\n",
      "[ 00:00:04.485 -->  00:00:19.842] B SPEAKER_01\n"
     ]
    }
   ],
   "source": [
    "from pyannote.audio import Pipeline\n",
    "import whisper\n",
    "\n",
    "audio = \"data/sample_two_people.wav\"\n",
    "pipeline = Pipeline.from_pretrained(\"pyannote/speaker-diarization\").to(determine_torch_device())\n",
    "\n",
    "diarization = pipeline(audio)\n",
    "\n",
    "print(diarization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<pyannote.core.annotation.Annotation at 0x3224ea060>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 00:00:00.030 -->  00:00:04.367]\n",
      "[ 00:00:04.485 -->  00:00:19.842]\n",
      "(<Segment(0.0309687, 4.36784)>, 'A', 'SPEAKER_00')\n",
      "(<Segment(4.48597, 19.8422)>, 'B', 'SPEAKER_01')\n"
     ]
    }
   ],
   "source": [
    "for segment in diarization.itersegments():\n",
    "    print(segment)\n",
    "\n",
    "for turn in diarization.itertracks(yield_label=True):\n",
    "    print(turn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seperate speaker segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'SPEAKER_00': [<Segment(0.0309687, 4.36784)>],\n",
       " 'SPEAKER_01': [<Segment(4.48597, 19.8422)>]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_speaker_segments(diarization):\n",
    "    segments = {}\n",
    "    for turn, _, speaker in diarization.itertracks(yield_label=True):\n",
    "        segments.setdefault(speaker, []).append(turn)\n",
    "    return segments\n",
    "\n",
    "\n",
    "diar_segments = get_speaker_segments(diarization)\n",
    "diar_segments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ask user, \"who is this?\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'jacob': [<Segment(0.0309687, 4.36784)>],\n",
       " 'cameron': [<Segment(4.48597, 19.8422)>]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# User assigns speakers to each segment\n",
    "diar_segments[\"jacob\"] = diar_segments.pop(\"SPEAKER_00\")\n",
    "diar_segments[\"cameron\"] = diar_segments.pop(\"SPEAKER_01\")\n",
    "\n",
    "\n",
    "diar_segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sglinton/dev/hub/.venv/lib/python3.12/site-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'id': 0,\n",
       "  'seek': 0,\n",
       "  'start': 0.0,\n",
       "  'end': 4.32,\n",
       "  'text': ' Okay, so, um, we were talking about that time Granddaddy slipped behind the stove.',\n",
       "  'tokens': [50364,\n",
       "   1033,\n",
       "   11,\n",
       "   370,\n",
       "   11,\n",
       "   1105,\n",
       "   11,\n",
       "   321,\n",
       "   645,\n",
       "   1417,\n",
       "   466,\n",
       "   300,\n",
       "   565,\n",
       "   6757,\n",
       "   20034,\n",
       "   3173,\n",
       "   28989,\n",
       "   2261,\n",
       "   264,\n",
       "   19263,\n",
       "   13,\n",
       "   50580],\n",
       "  'temperature': 0.0,\n",
       "  'avg_logprob': -0.3059328445280441,\n",
       "  'compression_ratio': 1.5466101694915255,\n",
       "  'no_speech_prob': 0.04611587896943092},\n",
       " {'id': 1,\n",
       "  'seek': 0,\n",
       "  'start': 4.48,\n",
       "  'end': 9.6,\n",
       "  'text': ' Yeah, that was in the summer because I remember it was hot, like real hot, like stick to your chair, hot.',\n",
       "  'tokens': [50588,\n",
       "   865,\n",
       "   11,\n",
       "   300,\n",
       "   390,\n",
       "   294,\n",
       "   264,\n",
       "   4266,\n",
       "   570,\n",
       "   286,\n",
       "   1604,\n",
       "   309,\n",
       "   390,\n",
       "   2368,\n",
       "   11,\n",
       "   411,\n",
       "   957,\n",
       "   2368,\n",
       "   11,\n",
       "   411,\n",
       "   2897,\n",
       "   281,\n",
       "   428,\n",
       "   6090,\n",
       "   11,\n",
       "   2368,\n",
       "   13,\n",
       "   50844],\n",
       "  'temperature': 0.0,\n",
       "  'avg_logprob': -0.3059328445280441,\n",
       "  'compression_ratio': 1.5466101694915255,\n",
       "  'no_speech_prob': 0.04611587896943092},\n",
       " {'id': 2,\n",
       "  'seek': 0,\n",
       "  'start': 10.0,\n",
       "  'end': 12.24,\n",
       "  'text': ' And Fio, you ran him from the backyard, right?',\n",
       "  'tokens': [50864,\n",
       "   400,\n",
       "   479,\n",
       "   1004,\n",
       "   11,\n",
       "   291,\n",
       "   5872,\n",
       "   796,\n",
       "   490,\n",
       "   264,\n",
       "   20036,\n",
       "   11,\n",
       "   558,\n",
       "   30,\n",
       "   50976],\n",
       "  'temperature': 0.0,\n",
       "  'avg_logprob': -0.3059328445280441,\n",
       "  'compression_ratio': 1.5466101694915255,\n",
       "  'no_speech_prob': 0.04611587896943092},\n",
       " {'id': 3,\n",
       "  'seek': 0,\n",
       "  'start': 12.72,\n",
       "  'end': 19.68,\n",
       "  'text': \" You had their muddy boots and mama yelled, not in my kitchen, boy, but you didn't even hear her because you saw him on the floor.\",\n",
       "  'tokens': [51000,\n",
       "   509,\n",
       "   632,\n",
       "   641,\n",
       "   38540,\n",
       "   15194,\n",
       "   293,\n",
       "   18775,\n",
       "   38023,\n",
       "   11,\n",
       "   406,\n",
       "   294,\n",
       "   452,\n",
       "   6525,\n",
       "   11,\n",
       "   3237,\n",
       "   11,\n",
       "   457,\n",
       "   291,\n",
       "   994,\n",
       "   380,\n",
       "   754,\n",
       "   1568,\n",
       "   720,\n",
       "   570,\n",
       "   291,\n",
       "   1866,\n",
       "   796,\n",
       "   322,\n",
       "   264,\n",
       "   4123,\n",
       "   13,\n",
       "   51348],\n",
       "  'temperature': 0.0,\n",
       "  'avg_logprob': -0.3059328445280441,\n",
       "  'compression_ratio': 1.5466101694915255,\n",
       "  'no_speech_prob': 0.04611587896943092}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = whisper.load_model(\"base\")\n",
    "\n",
    "results = model.transcribe(audio)\n",
    "results[\"segments\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the speaker based on the diarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jacob\n",
      "cameron\n",
      "cameron\n",
      "cameron\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'speaker': 'jacob',\n",
       "  'text': ' Okay, so, um, we were talking about that time Granddaddy slipped behind the stove.',\n",
       "  'start': 0.0,\n",
       "  'end': 4.32},\n",
       " {'speaker': 'cameron',\n",
       "  'text': ' Yeah, that was in the summer because I remember it was hot, like real hot, like stick to your chair, hot.',\n",
       "  'start': 4.48,\n",
       "  'end': 9.6},\n",
       " {'speaker': 'cameron',\n",
       "  'text': ' And Fio, you ran him from the backyard, right?',\n",
       "  'start': 10.0,\n",
       "  'end': 12.24},\n",
       " {'speaker': 'cameron',\n",
       "  'text': \" You had their muddy boots and mama yelled, not in my kitchen, boy, but you didn't even hear her because you saw him on the floor.\",\n",
       "  'start': 12.72,\n",
       "  'end': 19.68}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def assign_speakers(diarization_segments: dict, transcript_segments: dict):\n",
    "    diarization_list = []\n",
    "    for speaker, segs in diarization_segments.items():\n",
    "        for seg in segs:\n",
    "            diarization_list.append({'speaker': speaker, 'start': seg.start, 'end': seg.end})\n",
    "\n",
    "    speaker_transcript_list = []\n",
    "    for ts in transcript_segments:\n",
    "        mid = (ts[\"start\"] + ts[\"end\"]) / 2\n",
    "        # find the speaker that is closest to the midpoint\n",
    "        speaker = None\n",
    "\n",
    "        for seg in diarization_list:\n",
    "            if seg[\"start\"] <= mid <= seg[\"end\"]:\n",
    "                speaker = seg[\"speaker\"]\n",
    "                print(speaker)\n",
    "                break\n",
    "            speaker = \"UNKNOWN\"\n",
    "        \n",
    "        speaker_transcript_list.append({\"speaker\": speaker, \"text\": ts[\"text\"], \"start\": ts[\"start\"], \"end\": ts[\"end\"]})\n",
    "    \n",
    "    return speaker_transcript_list\n",
    "assigned = assign_speakers(diar_segments, results[\"segments\"])\n",
    "assigned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"jacob:  Okay, so, um, we were talking about that time Granddaddy slipped behind the stove. \\ncameron:  Yeah, that was in the summer because I remember it was hot, like real hot, like stick to your chair, hot.  And Fio, you ran him from the backyard, right?  You had their muddy boots and mama yelled, not in my kitchen, boy, but you didn't even hear her because you saw him on the floor.\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def rebuild_transcript(assigned_speakers: list):\n",
    "    transcript = \"\"\n",
    "    last_speaker = None\n",
    "    for speaker_data in assigned_speakers:\n",
    "        speaker = speaker_data[\"speaker\"]\n",
    "        if speaker != last_speaker:\n",
    "            transcript += f\"\\n{speaker}: \"\n",
    "        transcript += speaker_data[\"text\"] + \" \"\n",
    "        last_speaker = speaker\n",
    "    return transcript.strip()\n",
    "\n",
    "\n",
    "r_transcript = rebuild_transcript(assigned)\n",
    "r_transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:datasets:PyTorch version 2.7.1 available.\n",
      "INFO:sentence_transformers.SentenceTransformer:Use pytorch device_name: mps\n",
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "sentence_model = SentenceTransformer(\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'speaker': 'jacob',\n",
       "  'text': ' Okay, so, um, we were talking about that time Granddaddy slipped behind the stove.',\n",
       "  'start': 0.0,\n",
       "  'end': 4.32},\n",
       " {'speaker': 'cameron',\n",
       "  'text': \" Yeah, that was in the summer because I remember it was hot, like real hot, like stick to your chair, hot.  And Fio, you ran him from the backyard, right?  You had their muddy boots and mama yelled, not in my kitchen, boy, but you didn't even hear her because you saw him on the floor.\",\n",
       "  'start': 4.48,\n",
       "  'end': 19.68}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def merge_chunks(transcript, max_chars=300):\n",
    "    \"\"\"\n",
    "    Merge adjacent chunks until the chunk reaches max_chars or speaker changes.\n",
    "    transcript: list of dicts [{'speaker': ..., 'text': ..., ...}]\n",
    "    \"\"\"\n",
    "    merged = []\n",
    "    current_chunk = {\"speaker\": None, \"text\": \"\", \"start\": None, \"end\": None}\n",
    "    for entry in transcript:\n",
    "        # Start new chunk if speaker changes or current chunk too long\n",
    "        if (\n",
    "            current_chunk[\"speaker\"] != entry[\"speaker\"]\n",
    "            or len(current_chunk[\"text\"]) + len(entry[\"text\"]) > max_chars\n",
    "        ):\n",
    "            if current_chunk[\"speaker\"]:\n",
    "                merged.append(current_chunk.copy())\n",
    "            current_chunk = {\n",
    "                \"speaker\": entry[\"speaker\"],\n",
    "                \"text\": entry[\"text\"],\n",
    "                \"start\": entry[\"start\"],\n",
    "                \"end\": entry[\"end\"],\n",
    "            }\n",
    "        else:\n",
    "            current_chunk[\"text\"] += \" \" + entry[\"text\"]\n",
    "            current_chunk[\"end\"] = entry[\"end\"]\n",
    "    # Don't forget to add the last chunk\n",
    "    if current_chunk[\"speaker\"]:\n",
    "        merged.append(current_chunk)\n",
    "    return merged\n",
    "merged_chunks = merge_chunks(assigned)\n",
    "merged_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sentence_transformers.SentenceTransformer:Use pytorch device_name: mps\n",
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb0ed5b95c1348bd899693e379baa493",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2591b3c754144eec8251ff01f3d9996f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'speaker': 'jacob',\n",
       "  'text': ' Okay, so, um, we were talking about that time Granddaddy slipped behind the stove.',\n",
       "  'start': 0.0,\n",
       "  'end': 4.32,\n",
       "  'embedding': [0.03687985613942146,\n",
       "   0.07218573242425919,\n",
       "   -0.031606078147888184,\n",
       "   0.003955450840294361,\n",
       "   -0.017403479665517807,\n",
       "   -0.03887829929590225,\n",
       "   0.002273143269121647,\n",
       "   0.0004728688218165189,\n",
       "   -0.03914864733815193,\n",
       "   -0.07558505237102509,\n",
       "   0.03285520523786545,\n",
       "   0.07340769469738007,\n",
       "   -0.008757240138947964,\n",
       "   -0.020450251176953316,\n",
       "   -3.621853466029279e-05,\n",
       "   -0.09299337863922119,\n",
       "   -0.025853067636489868,\n",
       "   -0.05470428243279457,\n",
       "   -0.03168981894850731,\n",
       "   0.023129310458898544,\n",
       "   0.008257189765572548,\n",
       "   0.08070697635412216,\n",
       "   0.09470941871404648,\n",
       "   -0.013353965245187283,\n",
       "   0.024486225098371506,\n",
       "   0.06120988354086876,\n",
       "   0.0346834734082222,\n",
       "   0.0742507353425026,\n",
       "   0.05514067783951759,\n",
       "   0.07273170351982117,\n",
       "   0.023806395009160042,\n",
       "   -0.019037598744034767,\n",
       "   -0.10669765621423721,\n",
       "   0.0569484569132328,\n",
       "   -0.011150768958032131,\n",
       "   -0.046226367354393005,\n",
       "   -0.0043980712071061134,\n",
       "   0.1306905895471573,\n",
       "   0.009303675964474678,\n",
       "   0.03316724672913551,\n",
       "   0.060589924454689026,\n",
       "   -0.012109107337892056,\n",
       "   0.014066667295992374,\n",
       "   -0.07869452238082886,\n",
       "   -0.00978427566587925,\n",
       "   0.04944933205842972,\n",
       "   0.029510173946619034,\n",
       "   -0.11627750098705292,\n",
       "   -0.009221832267940044,\n",
       "   0.019123880192637444,\n",
       "   -0.029352113604545593,\n",
       "   0.070835180580616,\n",
       "   0.028507165610790253,\n",
       "   0.020818131044507027,\n",
       "   0.09408941119909286,\n",
       "   -0.0031714243814349174,\n",
       "   0.049018170684576035,\n",
       "   -0.014627189375460148,\n",
       "   0.011287111788988113,\n",
       "   0.013522494584321976,\n",
       "   -0.013138976879417896,\n",
       "   -0.010197323746979237,\n",
       "   -0.077619768679142,\n",
       "   0.048228051513433456,\n",
       "   0.004571747034788132,\n",
       "   -0.0886324942111969,\n",
       "   0.009110809303820133,\n",
       "   0.02673933282494545,\n",
       "   0.00973126757889986,\n",
       "   0.06444592028856277,\n",
       "   0.03427165374159813,\n",
       "   0.030829953029751778,\n",
       "   0.038757242262363434,\n",
       "   -0.03744496405124664,\n",
       "   -0.07950124144554138,\n",
       "   0.005948010832071304,\n",
       "   0.022792918607592583,\n",
       "   0.06490667909383774,\n",
       "   -0.009345744736492634,\n",
       "   -0.007839785888791084,\n",
       "   -0.010564482770860195,\n",
       "   0.013488695956766605,\n",
       "   -0.01082648616284132,\n",
       "   0.07661733776330948,\n",
       "   -0.09094637632369995,\n",
       "   -0.015539450570940971,\n",
       "   0.03329460322856903,\n",
       "   -0.019141005352139473,\n",
       "   -0.012552088126540184,\n",
       "   -0.043784160166978836,\n",
       "   0.03227357566356659,\n",
       "   -0.12395129352807999,\n",
       "   0.04995888099074364,\n",
       "   0.07392092794179916,\n",
       "   -0.0015321833780035377,\n",
       "   -0.08150407671928406,\n",
       "   0.0013773791724815965,\n",
       "   0.023101305589079857,\n",
       "   -0.05298514664173126,\n",
       "   -0.029596304520964622,\n",
       "   -0.07090310752391815,\n",
       "   0.06368096172809601,\n",
       "   -0.04376766458153725,\n",
       "   0.1121584102511406,\n",
       "   0.0051520089618861675,\n",
       "   0.041186150163412094,\n",
       "   -0.023767268285155296,\n",
       "   0.06707273423671722,\n",
       "   -0.008670145645737648,\n",
       "   0.0032953605987131596,\n",
       "   -0.019912254065275192,\n",
       "   0.005610909778624773,\n",
       "   0.009795003570616245,\n",
       "   -0.014512245543301105,\n",
       "   -0.0715690478682518,\n",
       "   -0.13243211805820465,\n",
       "   -0.010644293390214443,\n",
       "   -0.05122404545545578,\n",
       "   -0.09258633106946945,\n",
       "   -0.00770872738212347,\n",
       "   -0.0002753922308329493,\n",
       "   0.07324080914258957,\n",
       "   -0.012691326439380646,\n",
       "   0.11225878447294235,\n",
       "   -0.06966911256313324,\n",
       "   -0.08787732571363449,\n",
       "   0.10893727093935013,\n",
       "   -5.904918445177184e-33,\n",
       "   0.030533434823155403,\n",
       "   0.032205428928136826,\n",
       "   -0.06324567645788193,\n",
       "   0.013896004296839237,\n",
       "   0.08852072805166245,\n",
       "   0.057903554290533066,\n",
       "   -0.07406076788902283,\n",
       "   -0.009512553922832012,\n",
       "   -0.0047564138658344746,\n",
       "   0.06955768913030624,\n",
       "   0.08098459243774414,\n",
       "   -0.0458030104637146,\n",
       "   -0.0806150734424591,\n",
       "   -0.048372749239206314,\n",
       "   -0.03609718382358551,\n",
       "   0.08209899067878723,\n",
       "   -0.062472447752952576,\n",
       "   0.010970915667712688,\n",
       "   0.01497303880751133,\n",
       "   -0.08437490463256836,\n",
       "   -0.0731004998087883,\n",
       "   -0.013197447173297405,\n",
       "   0.06320545822381973,\n",
       "   0.03507329523563385,\n",
       "   -0.006351915188133717,\n",
       "   0.07863382250070572,\n",
       "   0.007969746366143227,\n",
       "   -0.003923672717064619,\n",
       "   -0.0138483215123415,\n",
       "   0.045685917139053345,\n",
       "   -0.01372190099209547,\n",
       "   0.012187054380774498,\n",
       "   -0.004578664433211088,\n",
       "   -0.015160910785198212,\n",
       "   -0.0009309651795774698,\n",
       "   0.06313791126012802,\n",
       "   0.03309342637658119,\n",
       "   -0.09582529962062836,\n",
       "   -0.018744414672255516,\n",
       "   -0.0009555116412229836,\n",
       "   -0.09148503094911575,\n",
       "   0.0013154421467334032,\n",
       "   0.013889569789171219,\n",
       "   0.08641505241394043,\n",
       "   -0.09117695689201355,\n",
       "   -0.010358682833611965,\n",
       "   0.04636966437101364,\n",
       "   0.0540398508310318,\n",
       "   -0.008521145209670067,\n",
       "   -0.011738554574549198,\n",
       "   -0.05481451749801636,\n",
       "   -0.015779465436935425,\n",
       "   0.027459729462862015,\n",
       "   -0.07835885882377625,\n",
       "   -0.09401223808526993,\n",
       "   0.0436817929148674,\n",
       "   0.02783283032476902,\n",
       "   0.02825898863375187,\n",
       "   0.08167186379432678,\n",
       "   0.07247325778007507,\n",
       "   0.002431402914226055,\n",
       "   0.05131550133228302,\n",
       "   0.015681248158216476,\n",
       "   -0.039667997509241104,\n",
       "   -0.07869011908769608,\n",
       "   -0.06751840561628342,\n",
       "   0.0004558911605272442,\n",
       "   0.0025662065017968416,\n",
       "   0.023966364562511444,\n",
       "   0.04250219091773033,\n",
       "   -0.02083980292081833,\n",
       "   -0.03302784636616707,\n",
       "   -0.07053932547569275,\n",
       "   -0.023412423208355904,\n",
       "   -0.023855486884713173,\n",
       "   0.04136447235941887,\n",
       "   0.06849461048841476,\n",
       "   -0.0270591638982296,\n",
       "   0.05917986482381821,\n",
       "   -0.08091205358505249,\n",
       "   0.05619368702173233,\n",
       "   -0.0695226788520813,\n",
       "   0.017421981319785118,\n",
       "   -0.018153589218854904,\n",
       "   -0.03350038453936577,\n",
       "   -0.01943644881248474,\n",
       "   -0.06517220288515091,\n",
       "   0.041806504130363464,\n",
       "   -0.010758318938314915,\n",
       "   0.08483804017305374,\n",
       "   -0.07257795333862305,\n",
       "   -0.005397814325988293,\n",
       "   0.07927193492650986,\n",
       "   -0.05217396840453148,\n",
       "   -0.03828366473317146,\n",
       "   2.049811987942535e-33,\n",
       "   0.01599917560815811,\n",
       "   0.07134382426738739,\n",
       "   0.009526810608804226,\n",
       "   0.03966767340898514,\n",
       "   0.07576510310173035,\n",
       "   -0.07944446802139282,\n",
       "   -0.0610044002532959,\n",
       "   -0.019961506128311157,\n",
       "   -0.033565226942300797,\n",
       "   -0.060975294560194016,\n",
       "   0.0019091236172243953,\n",
       "   -0.0397665798664093,\n",
       "   -0.012142867781221867,\n",
       "   0.03859585151076317,\n",
       "   0.04069184884428978,\n",
       "   0.06969321519136429,\n",
       "   0.038850005716085434,\n",
       "   0.0031313938088715076,\n",
       "   0.0035125743597745895,\n",
       "   0.01722603105008602,\n",
       "   -0.04438389837741852,\n",
       "   -0.017460154369473457,\n",
       "   -0.09118693321943283,\n",
       "   0.02718009427189827,\n",
       "   -0.036687180399894714,\n",
       "   -0.0001497551565989852,\n",
       "   0.03624527528882027,\n",
       "   0.005509365350008011,\n",
       "   -0.15661869943141937,\n",
       "   -0.030349766835570335,\n",
       "   -0.008734457194805145,\n",
       "   -0.0634707361459732,\n",
       "   -0.05397315323352814,\n",
       "   -0.00429095234721899,\n",
       "   -0.008148337714374065,\n",
       "   0.04458778724074364,\n",
       "   0.012323458679020405,\n",
       "   -0.013836556114256382,\n",
       "   -0.06718482822179794,\n",
       "   -0.09485331922769547,\n",
       "   0.027912931516766548,\n",
       "   -0.026631755754351616,\n",
       "   -0.04216134175658226,\n",
       "   0.12149322777986526,\n",
       "   -0.019209353253245354,\n",
       "   0.0034182246308773756,\n",
       "   -0.07047011703252792,\n",
       "   0.08944569528102875,\n",
       "   0.10481784492731094,\n",
       "   0.10869436711072922,\n",
       "   -0.046661682426929474,\n",
       "   -0.029984332621097565,\n",
       "   0.08457142114639282,\n",
       "   -0.01958794891834259,\n",
       "   -0.017808223143219948,\n",
       "   -0.04388856515288353,\n",
       "   0.07944837957620621,\n",
       "   -0.1019335463643074,\n",
       "   -0.08857238292694092,\n",
       "   0.013317469507455826,\n",
       "   0.04384306073188782,\n",
       "   -0.00044709484791383147,\n",
       "   0.011270061135292053,\n",
       "   -0.025400863960385323,\n",
       "   -0.011854746378958225,\n",
       "   0.07740448415279388,\n",
       "   -0.07521160691976547,\n",
       "   0.03695201128721237,\n",
       "   -0.020748363807797432,\n",
       "   0.036386698484420776,\n",
       "   0.0922190248966217,\n",
       "   0.0016330060316249728,\n",
       "   -0.04535079747438431,\n",
       "   -0.05106405168771744,\n",
       "   0.00644092308357358,\n",
       "   0.07901739329099655,\n",
       "   -0.046484850347042084,\n",
       "   0.0027778807561844587,\n",
       "   -0.029378555715084076,\n",
       "   -0.06069121137261391,\n",
       "   0.05178847536444664,\n",
       "   -0.009487939067184925,\n",
       "   -0.029729586094617844,\n",
       "   -0.015395695343613625,\n",
       "   -0.040833376348018646,\n",
       "   -0.08050201833248138,\n",
       "   -0.018925901502370834,\n",
       "   -0.027738377451896667,\n",
       "   -0.05604599788784981,\n",
       "   -0.04548923671245575,\n",
       "   0.02408035844564438,\n",
       "   -0.07590732723474503,\n",
       "   0.10239390283823013,\n",
       "   -0.03065517358481884,\n",
       "   -0.015527286566793919,\n",
       "   -2.8780982930243226e-08,\n",
       "   -0.02086712419986725,\n",
       "   0.053102679550647736,\n",
       "   0.03638811782002449,\n",
       "   -0.0194486603140831,\n",
       "   0.012544370256364346,\n",
       "   -0.04518689587712288,\n",
       "   0.05060001090168953,\n",
       "   -0.009740076027810574,\n",
       "   0.015219747088849545,\n",
       "   -0.013169019483029842,\n",
       "   -0.03891058266162872,\n",
       "   0.03741178661584854,\n",
       "   0.11338846385478973,\n",
       "   0.08341774344444275,\n",
       "   0.08012368530035019,\n",
       "   -0.019551323726773262,\n",
       "   -0.0030779163353145123,\n",
       "   -0.10141123086214066,\n",
       "   -0.05145543813705444,\n",
       "   0.04317215457558632,\n",
       "   0.035136230289936066,\n",
       "   0.010369496420025826,\n",
       "   0.017220513895154,\n",
       "   0.03438489884138107,\n",
       "   0.03940850496292114,\n",
       "   -0.001974220387637615,\n",
       "   -0.010845146141946316,\n",
       "   0.025059334933757782,\n",
       "   0.026559466496109962,\n",
       "   0.019810952246189117,\n",
       "   0.025251133367419243,\n",
       "   0.014942971058189869,\n",
       "   -0.06171133369207382,\n",
       "   0.04679841920733452,\n",
       "   -0.021646805107593536,\n",
       "   -0.06454694271087646,\n",
       "   0.05884326249361038,\n",
       "   0.01305701769888401,\n",
       "   0.001428757095709443,\n",
       "   -0.08723181486129761,\n",
       "   -0.03706035390496254,\n",
       "   0.023749109357595444,\n",
       "   0.012194777838885784,\n",
       "   0.04157233610749245,\n",
       "   -0.0001670758065301925,\n",
       "   0.01536660548299551,\n",
       "   -0.024944595992565155,\n",
       "   0.034136511385440826,\n",
       "   -0.04834626987576485,\n",
       "   0.0466025210916996,\n",
       "   0.04154597222805023,\n",
       "   0.0251380056142807,\n",
       "   0.07014283537864685,\n",
       "   0.06022389978170395,\n",
       "   0.0731796994805336,\n",
       "   -0.10836190730333328,\n",
       "   -0.01832910068333149,\n",
       "   -0.04235553368926048,\n",
       "   -0.026384824886918068,\n",
       "   -0.02860579825937748,\n",
       "   0.0014478310476988554,\n",
       "   0.03332935646176338,\n",
       "   0.008991166949272156,\n",
       "   -0.007926602847874165]},\n",
       " {'speaker': 'cameron',\n",
       "  'text': \" Yeah, that was in the summer because I remember it was hot, like real hot, like stick to your chair, hot.  And Fio, you ran him from the backyard, right?  You had their muddy boots and mama yelled, not in my kitchen, boy, but you didn't even hear her because you saw him on the floor.\",\n",
       "  'start': 4.48,\n",
       "  'end': 19.68,\n",
       "  'embedding': [0.04271169379353523,\n",
       "   0.017093783244490623,\n",
       "   0.02117336541414261,\n",
       "   0.07392027229070663,\n",
       "   0.0588611476123333,\n",
       "   -0.08049070835113525,\n",
       "   0.03642548620700836,\n",
       "   -0.010500488802790642,\n",
       "   -0.0607408732175827,\n",
       "   0.006509239785373211,\n",
       "   0.052886784076690674,\n",
       "   -0.02956126257777214,\n",
       "   0.10548055917024612,\n",
       "   0.07898937910795212,\n",
       "   0.040082648396492004,\n",
       "   0.0629202127456665,\n",
       "   0.12002407759428024,\n",
       "   0.034063614904880524,\n",
       "   0.013220306485891342,\n",
       "   0.014305910095572472,\n",
       "   -0.029624750837683678,\n",
       "   0.06346096098423004,\n",
       "   0.0204826258122921,\n",
       "   0.024322841316461563,\n",
       "   -0.004545739386230707,\n",
       "   0.030295507982373238,\n",
       "   0.05235571041703224,\n",
       "   0.0832967534661293,\n",
       "   -0.05474962294101715,\n",
       "   0.054296284914016724,\n",
       "   -0.007331816479563713,\n",
       "   -0.030114414170384407,\n",
       "   0.01059124805033207,\n",
       "   -0.03034599870443344,\n",
       "   0.0021581046748906374,\n",
       "   0.00010115031182067469,\n",
       "   -0.02122686803340912,\n",
       "   -0.03741752728819847,\n",
       "   -0.06246238574385643,\n",
       "   0.0006361678242683411,\n",
       "   -0.0154378367587924,\n",
       "   0.014506729319691658,\n",
       "   0.0709216296672821,\n",
       "   -0.06517894566059113,\n",
       "   -0.005934388842433691,\n",
       "   0.002515255007892847,\n",
       "   -0.012954618781805038,\n",
       "   -0.029967011883854866,\n",
       "   0.08457201719284058,\n",
       "   -0.030237575992941856,\n",
       "   0.008053800091147423,\n",
       "   0.04902893677353859,\n",
       "   0.0419335812330246,\n",
       "   0.010069571435451508,\n",
       "   -0.0564519464969635,\n",
       "   0.014278629794716835,\n",
       "   0.07530888170003891,\n",
       "   -0.047724563628435135,\n",
       "   0.029742540791630745,\n",
       "   0.04103571176528931,\n",
       "   -0.03941620886325836,\n",
       "   0.03783578798174858,\n",
       "   -0.024347666651010513,\n",
       "   0.008420783095061779,\n",
       "   0.034372664988040924,\n",
       "   -0.0718531608581543,\n",
       "   -0.03417717665433884,\n",
       "   -0.03667796030640602,\n",
       "   0.03678163141012192,\n",
       "   0.07251987606287003,\n",
       "   -0.004179427400231361,\n",
       "   0.0627032220363617,\n",
       "   0.040142931044101715,\n",
       "   -0.0431550107896328,\n",
       "   -0.08106305450201035,\n",
       "   0.04181171581149101,\n",
       "   -0.022020451724529266,\n",
       "   -0.011040935292840004,\n",
       "   0.030802128836512566,\n",
       "   0.007228805683553219,\n",
       "   0.0033729812130331993,\n",
       "   -0.07397297024726868,\n",
       "   0.0022419497836381197,\n",
       "   -0.00045539732673205435,\n",
       "   -0.008699013851583004,\n",
       "   -0.020030703395605087,\n",
       "   0.08612517267465591,\n",
       "   -0.07933811098337173,\n",
       "   -0.027974087744951248,\n",
       "   -0.0047597456723451614,\n",
       "   -0.07399345934391022,\n",
       "   -0.043493784964084625,\n",
       "   -0.044695571064949036,\n",
       "   0.02367611974477768,\n",
       "   0.012863327749073505,\n",
       "   -0.07907360792160034,\n",
       "   -0.043873537331819534,\n",
       "   0.03589320555329323,\n",
       "   0.011136180721223354,\n",
       "   0.0016072482103481889,\n",
       "   0.007099604699760675,\n",
       "   -0.004938790574669838,\n",
       "   -0.06814958900213242,\n",
       "   -0.010353902354836464,\n",
       "   0.07353980094194412,\n",
       "   0.04020942002534866,\n",
       "   0.04251503944396973,\n",
       "   0.008112450130283833,\n",
       "   -0.0018843460129573941,\n",
       "   0.029390370473265648,\n",
       "   -0.025253232568502426,\n",
       "   -0.045226264744997025,\n",
       "   0.021230239421129227,\n",
       "   0.011492476798593998,\n",
       "   0.006703358143568039,\n",
       "   -0.14806805551052094,\n",
       "   0.011042075231671333,\n",
       "   -0.048834655433893204,\n",
       "   -0.07584980875253677,\n",
       "   -0.009651919826865196,\n",
       "   0.045125655829906464,\n",
       "   0.0405501052737236,\n",
       "   -0.018674900755286217,\n",
       "   0.07500207424163818,\n",
       "   0.03617968410253525,\n",
       "   -0.11379006505012512,\n",
       "   0.06954918056726456,\n",
       "   -3.731282453712922e-33,\n",
       "   0.030914155766367912,\n",
       "   -0.011042360216379166,\n",
       "   -0.06257112324237823,\n",
       "   -0.03793347254395485,\n",
       "   0.24217146635055542,\n",
       "   -0.017205340787768364,\n",
       "   0.029269447550177574,\n",
       "   0.007612789049744606,\n",
       "   -0.011188492178916931,\n",
       "   0.04563749581575394,\n",
       "   -0.010024153627455235,\n",
       "   -0.007618364412337542,\n",
       "   -0.015427252277731895,\n",
       "   -0.06619865447282791,\n",
       "   0.008657771162688732,\n",
       "   0.04455867037177086,\n",
       "   -0.08782736212015152,\n",
       "   -0.007545375730842352,\n",
       "   0.006220423616468906,\n",
       "   0.07709362357854843,\n",
       "   -0.06995615363121033,\n",
       "   0.07199987024068832,\n",
       "   0.047256406396627426,\n",
       "   -0.004409495275467634,\n",
       "   0.006209694780409336,\n",
       "   0.056182898581027985,\n",
       "   -0.02390618622303009,\n",
       "   8.900537068257108e-06,\n",
       "   0.04916175454854965,\n",
       "   0.030532389879226685,\n",
       "   0.005647650919854641,\n",
       "   0.007204433903098106,\n",
       "   0.02885228581726551,\n",
       "   0.01868831180036068,\n",
       "   -0.006322596222162247,\n",
       "   -0.07041014730930328,\n",
       "   0.05930190905928612,\n",
       "   -0.04241059347987175,\n",
       "   -0.09274256974458694,\n",
       "   0.05478838458657265,\n",
       "   0.006717211566865444,\n",
       "   -0.0530935600399971,\n",
       "   0.06254533678293228,\n",
       "   -0.04502187669277191,\n",
       "   -0.09165158122777939,\n",
       "   0.018914617598056793,\n",
       "   -0.022890493273735046,\n",
       "   0.10955695807933807,\n",
       "   -0.050683386623859406,\n",
       "   -0.04881759732961655,\n",
       "   -0.00771291134878993,\n",
       "   0.00454981904476881,\n",
       "   0.0602567121386528,\n",
       "   -0.055229660123586655,\n",
       "   0.025232793763279915,\n",
       "   0.03983912616968155,\n",
       "   0.04990775138139725,\n",
       "   -0.05137425288558006,\n",
       "   0.04395608231425285,\n",
       "   0.002537904540076852,\n",
       "   -0.016072213649749756,\n",
       "   0.04266117513179779,\n",
       "   0.06713087856769562,\n",
       "   -0.08094992488622665,\n",
       "   -0.09353592246770859,\n",
       "   -0.1807115077972412,\n",
       "   -0.0037079534959048033,\n",
       "   0.07153962552547455,\n",
       "   0.010549869388341904,\n",
       "   -0.019182933494448662,\n",
       "   0.08614961802959442,\n",
       "   0.03080010414123535,\n",
       "   -0.10909391194581985,\n",
       "   -0.03350792080163956,\n",
       "   0.05996526777744293,\n",
       "   -0.03539934381842613,\n",
       "   0.05701898783445358,\n",
       "   -0.012856516987085342,\n",
       "   -0.07694006711244583,\n",
       "   -0.0717683881521225,\n",
       "   0.10398156940937042,\n",
       "   -0.05750967562198639,\n",
       "   0.040097542107105255,\n",
       "   0.01113793533295393,\n",
       "   -0.022293658927083015,\n",
       "   -0.04876987263560295,\n",
       "   0.017227279022336006,\n",
       "   -0.04065931215882301,\n",
       "   -0.03559939190745354,\n",
       "   0.004296119324862957,\n",
       "   -0.06777092069387436,\n",
       "   -0.0035262713208794594,\n",
       "   0.023979702964425087,\n",
       "   -0.03764694929122925,\n",
       "   0.007641128730028868,\n",
       "   7.396035049576171e-34,\n",
       "   0.04782422259449959,\n",
       "   0.10118275135755539,\n",
       "   0.05099443718791008,\n",
       "   -2.145462167391088e-05,\n",
       "   0.023687170818448067,\n",
       "   -0.07169678807258606,\n",
       "   -0.04962523281574249,\n",
       "   0.007911046966910362,\n",
       "   0.015354265458881855,\n",
       "   0.012139396741986275,\n",
       "   -0.014149240218102932,\n",
       "   -0.055753592401742935,\n",
       "   -0.00876528862863779,\n",
       "   -0.057789843529462814,\n",
       "   0.04988693818449974,\n",
       "   -0.007840119302272797,\n",
       "   -0.06443161517381668,\n",
       "   0.04475013166666031,\n",
       "   -0.005520174745470285,\n",
       "   0.021147968247532845,\n",
       "   -0.053313057869672775,\n",
       "   -0.03726760670542717,\n",
       "   0.0763811394572258,\n",
       "   0.050686728209257126,\n",
       "   -0.061685845255851746,\n",
       "   -0.03571980819106102,\n",
       "   0.01352725364267826,\n",
       "   0.028965028002858162,\n",
       "   -0.04256027936935425,\n",
       "   0.020319756120443344,\n",
       "   -0.029244467616081238,\n",
       "   -0.051232196390628815,\n",
       "   0.021817738190293312,\n",
       "   -0.04144567996263504,\n",
       "   -0.06806563585996628,\n",
       "   0.017941638827323914,\n",
       "   -0.03663414716720581,\n",
       "   -0.031324658542871475,\n",
       "   -0.00028849230147898197,\n",
       "   -0.052865952253341675,\n",
       "   0.06091301143169403,\n",
       "   -0.0607098825275898,\n",
       "   0.01447648461908102,\n",
       "   0.05304491147398949,\n",
       "   -0.025120627135038376,\n",
       "   -0.0116158751770854,\n",
       "   -0.07947150617837906,\n",
       "   -0.01713997684419155,\n",
       "   -0.02652920037508011,\n",
       "   -0.01083766296505928,\n",
       "   -0.028914853930473328,\n",
       "   0.008817396126687527,\n",
       "   -0.0583924800157547,\n",
       "   0.056454431265592575,\n",
       "   -0.08444000035524368,\n",
       "   -0.07066729664802551,\n",
       "   0.062408626079559326,\n",
       "   0.04442758113145828,\n",
       "   -0.011610842309892178,\n",
       "   0.017569273710250854,\n",
       "   -0.016767969354987144,\n",
       "   0.0038936096243560314,\n",
       "   -0.084392249584198,\n",
       "   0.011886362917721272,\n",
       "   0.01612490601837635,\n",
       "   0.04939708486199379,\n",
       "   -0.08920227736234665,\n",
       "   -0.07445887476205826,\n",
       "   -0.056689340621232986,\n",
       "   0.02960994653403759,\n",
       "   -0.001707375282421708,\n",
       "   -0.0066971248015761375,\n",
       "   -0.1077612042427063,\n",
       "   0.1115473136305809,\n",
       "   0.03757461532950401,\n",
       "   -0.006277698092162609,\n",
       "   -0.072788767516613,\n",
       "   -0.03215865045785904,\n",
       "   -0.0076558152213692665,\n",
       "   0.014440084807574749,\n",
       "   -0.02764519490301609,\n",
       "   -0.0005323155783116817,\n",
       "   -0.03310530260205269,\n",
       "   0.052158962935209274,\n",
       "   0.005959733389317989,\n",
       "   -0.042649924755096436,\n",
       "   -0.02572784200310707,\n",
       "   -0.04948802292346954,\n",
       "   -0.02899157628417015,\n",
       "   -0.012468540109694004,\n",
       "   0.11018293350934982,\n",
       "   0.023215727880597115,\n",
       "   0.07003584504127502,\n",
       "   0.01734142005443573,\n",
       "   -0.06825914233922958,\n",
       "   -3.9888686131916984e-08,\n",
       "   -0.04043620079755783,\n",
       "   0.089429572224617,\n",
       "   0.0009605527739040554,\n",
       "   -0.04350791126489639,\n",
       "   0.05394793674349785,\n",
       "   -0.016121577471494675,\n",
       "   0.0366847962141037,\n",
       "   -0.025415129959583282,\n",
       "   0.03192488104104996,\n",
       "   -0.005031153559684753,\n",
       "   -0.07902300357818604,\n",
       "   0.027551358565688133,\n",
       "   0.06800732761621475,\n",
       "   0.12040077149868011,\n",
       "   0.07184145599603653,\n",
       "   0.013655352406203747,\n",
       "   0.05535693094134331,\n",
       "   -0.0887736827135086,\n",
       "   0.001065049204044044,\n",
       "   0.02252846583724022,\n",
       "   -0.002991884481161833,\n",
       "   0.07496165484189987,\n",
       "   0.03846744820475578,\n",
       "   0.11509256064891815,\n",
       "   -0.008745452389121056,\n",
       "   0.011342039331793785,\n",
       "   -0.039962708950042725,\n",
       "   0.008682992309331894,\n",
       "   0.08221860229969025,\n",
       "   0.057758629322052,\n",
       "   -0.00710640661418438,\n",
       "   -0.0032488235738128424,\n",
       "   -0.04983832314610481,\n",
       "   -0.04021254554390907,\n",
       "   -0.09093454480171204,\n",
       "   -0.007084032520651817,\n",
       "   0.06383310258388519,\n",
       "   -0.0016080037457868457,\n",
       "   0.02822382003068924,\n",
       "   -0.061813242733478546,\n",
       "   -0.06055496260523796,\n",
       "   -0.034946080297231674,\n",
       "   0.021401623263955116,\n",
       "   -0.05566452816128731,\n",
       "   0.009877137839794159,\n",
       "   0.05642566829919815,\n",
       "   -0.03702510520815849,\n",
       "   -0.06234894320368767,\n",
       "   0.01112793292850256,\n",
       "   0.06128545477986336,\n",
       "   -0.04651457071304321,\n",
       "   0.02217938005924225,\n",
       "   -0.022535964846611023,\n",
       "   0.035940591245889664,\n",
       "   0.07140237092971802,\n",
       "   -0.15225140750408173,\n",
       "   -0.04055622220039368,\n",
       "   -0.05450398102402687,\n",
       "   0.04170297086238861,\n",
       "   -0.018506553024053574,\n",
       "   0.03583228960633278,\n",
       "   0.06939270347356796,\n",
       "   -0.08063364028930664,\n",
       "   0.0003255748306401074]}]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "for chunk in merged_chunks:\n",
    "    chunk[\"embedding\"] = model.encode(chunk[\"text\"]).tolist()\n",
    "merged_chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector DB (faiss not working on 3.12?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:chromadb.telemetry.product.posthog:Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.\n",
      "INFO:httpx:HTTP Request: GET http://localhost:8000/api/v2/auth/identity \"HTTP/1.1 200 OK\"\n",
      "INFO:chromadb.telemetry.product.posthog:Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.\n",
      "INFO:httpx:HTTP Request: GET http://localhost:8000/api/v2/tenants/default_tenant \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://localhost:8000/api/v2/tenants/default_tenant/databases/default_database \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8000/api/v2/tenants/default_tenant/databases/default_database/collections \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://localhost:8000/api/v2/pre-flight-checks \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8000/api/v2/tenants/default_tenant/databases/default_database/collections/bc221242-d20f-4d2b-afc9-0d8c95b61209/add \"HTTP/1.1 201 Created\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8000/api/v2/tenants/default_tenant/databases/default_database/collections/bc221242-d20f-4d2b-afc9-0d8c95b61209/add \"HTTP/1.1 201 Created\"\n"
     ]
    }
   ],
   "source": [
    "import chromadb\n",
    "\n",
    "client = chromadb.HttpClient(host=\"localhost\", port=8000)\n",
    "collection = client.create_collection(\"family_stories\")\n",
    "for i, chunk in enumerate(merged_chunks):\n",
    "    collection.add(\n",
    "        ids=[f\"chunk_{i}\"],\n",
    "        documents=[chunk[\"text\"]],\n",
    "        metadatas=[\n",
    "            {\"speaker\": chunk[\"speaker\"], \"start\": chunk[\"start\"], \"end\": chunk[\"end\"]}\n",
    "        ],\n",
    "        embeddings=[chunk[\"embedding\"]],\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sentence_transformers.SentenceTransformer:Use pytorch device_name: mps\n",
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d5f26e9584e4c9ca6cecff6b0f48824",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://localhost:8000/api/v2/tenants/default_tenant/databases/default_database/collections/bc221242-d20f-4d2b-afc9-0d8c95b61209/query \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ids': [['chunk_0', 'chunk_1']],\n",
       " 'distances': [[0.774191, 1.5147762]],\n",
       " 'embeddings': None,\n",
       " 'metadatas': [[{'end': 4.32, 'speaker': 'jacob', 'start': 0.0},\n",
       "   {'speaker': 'cameron', 'start': 4.48, 'end': 19.68}]],\n",
       " 'documents': [[' Okay, so, um, we were talking about that time Granddaddy slipped behind the stove.',\n",
       "   \" Yeah, that was in the summer because I remember it was hot, like real hot, like stick to your chair, hot.  And Fio, you ran him from the backyard, right?  You had their muddy boots and mama yelled, not in my kitchen, boy, but you didn't even hear her because you saw him on the floor.\"]],\n",
       " 'uris': None,\n",
       " 'data': None,\n",
       " 'included': ['metadatas', 'documents', 'distances']}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "query = \"Tell me about granddays story behind the stove?\"\n",
    "\n",
    "query_embedding = model.encode(query).tolist()\n",
    "results = collection.query(\n",
    "    query_embeddings=[query_embedding],\n",
    "    n_results=3,\n",
    ")\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'speaker': 'jacob',\n",
       "  'text': ' Okay, so, um, we were talking about that time Granddaddy slipped behind the stove.',\n",
       "  'start': 0.0,\n",
       "  'end': 4.32},\n",
       " {'speaker': 'cameron',\n",
       "  'text': \" Yeah, that was in the summer because I remember it was hot, like real hot, like stick to your chair, hot.  And Fio, you ran him from the backyard, right?  You had their muddy boots and mama yelled, not in my kitchen, boy, but you didn't even hear her because you saw him on the floor.\",\n",
       "  'start': 4.48,\n",
       "  'end': 19.68}]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def merge_chunks(transcript, max_chars=300):\n",
    "    \"\"\"\n",
    "    Merge adjacent chunks until the chunk reaches max_chars or speaker changes.\n",
    "    transcript: list of dicts [{'speaker': ..., 'text': ..., ...}]\n",
    "    \"\"\"\n",
    "    merged = []\n",
    "    current_chunk = {\"speaker\": None, \"text\": \"\", \"start\": None, \"end\": None}\n",
    "    for entry in transcript:\n",
    "        # Start new chunk if speaker changes or current chunk too long\n",
    "        if (\n",
    "            current_chunk[\"speaker\"] != entry[\"speaker\"]\n",
    "            or len(current_chunk[\"text\"]) + len(entry[\"text\"]) > max_chars\n",
    "        ):\n",
    "            if current_chunk[\"speaker\"]:\n",
    "                merged.append(current_chunk.copy())\n",
    "            current_chunk = {\n",
    "                \"speaker\": entry[\"speaker\"],\n",
    "                \"text\": entry[\"text\"],\n",
    "                \"start\": entry[\"start\"],\n",
    "                \"end\": entry[\"end\"],\n",
    "            }\n",
    "        else:\n",
    "            current_chunk[\"text\"] += \" \" + entry[\"text\"]\n",
    "            current_chunk[\"end\"] = entry[\"end\"]\n",
    "    # Don't forget to add the last chunk\n",
    "    if current_chunk[\"speaker\"]:\n",
    "        merged.append(current_chunk)\n",
    "    return merged\n",
    "merged_chunks = merge_chunks(assigned)\n",
    "merged_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"jacob: Okay, so, um, we were talking about that time Granddaddy slipped behind the stove.\\ncameron: Yeah, that was in the summer because I remember it was hot, like real hot, like stick to your chair, hot.  And Fio, you ran him from the backyard, right?  You had their muddy boots and mama yelled, not in my kitchen, boy, but you didn't even hear her because you saw him on the floor.\""
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = results[\"documents\"][0]\n",
    "metas = results[\"metadatas\"][0]\n",
    "\n",
    "rag_chunks = [\n",
    "    f\"{meta['speaker']}: {doc.strip()}\"\n",
    "    for meta, doc in zip(metas, docs)\n",
    "]\n",
    "rag_context = \"\\n\".join(rag_chunks)\n",
    "\n",
    "rag_context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://localhost:8321/v1/inference/chat-completion \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "chat = client.inference.chat_completion(\n",
    "    model_id=model,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are an assistant summarizing information about a family's preserved story. Don't speak in first person. Context is transcribed family members audio recordings, so it is not always clear who is speaking. Only use information from the context to answer the question.\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"Context: {rag_context}\\n Question: Whats the story of grandad in the kitchen?\\n Answer:\",\n",
    "        },\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'According to the audio recording, it appears that Granddaddy slipped behind the stove while cooking. Cameron remembers it was a hot summer day and Fio (likely a young child) ran after Granddaddy from the backyard, wearing muddy boots, which caused Mama to yell at him not to be in the kitchen.'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.completion_message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
