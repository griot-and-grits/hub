{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing transcriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "okay so um we were talkin about that time granddaddy slipped behind the stove yeah that was in the s\n"
     ]
    }
   ],
   "source": [
    "def get_transcript(file_name: str):\n",
    "    return open(file_name, \"r\").read()\n",
    "\n",
    "\n",
    "transcript = get_transcript(\"data/mcclendon_tapes.txt\")\n",
    "print(transcript[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensure LLS is active + the model we are using to test exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET http://localhost:8321/v1/models \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "from llama_stack_client import LlamaStackClient\n",
    "\n",
    "model = \"llama3.2:1b\"\n",
    "client = LlamaStackClient(\n",
    "    base_url=\"http://localhost:8321\"\n",
    ")\n",
    "\n",
    "models = client.models.list()\n",
    "assert model in [m.identifier for m in models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://localhost:8321/v1/inference/chat-completion \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ChatCompletionResponse(completion_message=CompletionMessage(content=\"This conversation has just begun. There is no transcript to share yet. What would you like to talk about or ask? I can summarize our conversation at the end if you'd like.\", role='assistant', stop_reason='end_of_turn', tool_calls=[]), logprobs=None, metrics=[Metric(metric='prompt_tokens', value=15.0, unit=None), Metric(metric='completion_tokens', value=47.0, unit=None), Metric(metric='total_tokens', value=62.0, unit=None)])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.inference.chat_completion(model_id=model, messages=[{\"role\": \"user\", \"content\": \"What is the transcript?\"}])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine GPU to use, if not default to CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def determine_torch_device():\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device(\"cuda\")\n",
    "    elif torch.backends.mps.is_available():\n",
    "        return torch.device(\"mps\")\n",
    "    else:\n",
    "        return torch.device(\"cpu\")\n",
    "\n",
    "device = determine_torch_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.5.1.post0. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../../../.cache/torch/pyannote/models--pyannote--segmentation/snapshots/c4c8ceafcbb3a7a280c2d357aee9fbc9b0be7f9b/pytorch_model.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.3.2. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.7.1. Bad things might happen unless you revert torch to 1.x.\n",
      "[ 00:00:00.030 -->  00:00:04.367] A SPEAKER_00\n",
      "[ 00:00:04.485 -->  00:00:19.842] B SPEAKER_01\n"
     ]
    }
   ],
   "source": [
    "from pyannote.audio import Pipeline\n",
    "import whisper\n",
    "\n",
    "audio = \"data/sample_two_people.wav\"\n",
    "pipeline = Pipeline.from_pretrained(\"pyannote/speaker-diarization\").to(determine_torch_device())\n",
    "\n",
    "diarization = pipeline(audio)\n",
    "\n",
    "print(diarization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<pyannote.core.annotation.Annotation at 0x42d6434a0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 00:00:00.030 -->  00:00:04.367]\n",
      "[ 00:00:04.485 -->  00:00:19.842]\n",
      "(<Segment(0.0309687, 4.36784)>, 'A', 'SPEAKER_00')\n",
      "(<Segment(4.48597, 19.8422)>, 'B', 'SPEAKER_01')\n"
     ]
    }
   ],
   "source": [
    "for segment in diarization.itersegments():\n",
    "    print(segment)\n",
    "\n",
    "for turn in diarization.itertracks(yield_label=True):\n",
    "    print(turn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seperate speaker segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'SPEAKER_00': [<Segment(0.0309687, 4.36784)>],\n",
       " 'SPEAKER_01': [<Segment(4.48597, 19.8422)>]}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_speaker_segments(diarization):\n",
    "    segments = {}\n",
    "    for turn, _, speaker in diarization.itertracks(yield_label=True):\n",
    "        segments.setdefault(speaker, []).append(turn)\n",
    "    return segments\n",
    "\n",
    "\n",
    "diar_segments = get_speaker_segments(diarization)\n",
    "diar_segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sglinton/dev/hub/.venv/lib/python3.12/site-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'id': 0,\n",
       "  'seek': 0,\n",
       "  'start': 0.0,\n",
       "  'end': 4.32,\n",
       "  'text': ' Okay, so, um, we were talking about that time Granddaddy slipped behind the stove.',\n",
       "  'tokens': [50364,\n",
       "   1033,\n",
       "   11,\n",
       "   370,\n",
       "   11,\n",
       "   1105,\n",
       "   11,\n",
       "   321,\n",
       "   645,\n",
       "   1417,\n",
       "   466,\n",
       "   300,\n",
       "   565,\n",
       "   6757,\n",
       "   20034,\n",
       "   3173,\n",
       "   28989,\n",
       "   2261,\n",
       "   264,\n",
       "   19263,\n",
       "   13,\n",
       "   50580],\n",
       "  'temperature': 0.0,\n",
       "  'avg_logprob': -0.3059328445280441,\n",
       "  'compression_ratio': 1.5466101694915255,\n",
       "  'no_speech_prob': 0.04611587896943092},\n",
       " {'id': 1,\n",
       "  'seek': 0,\n",
       "  'start': 4.48,\n",
       "  'end': 9.6,\n",
       "  'text': ' Yeah, that was in the summer because I remember it was hot, like real hot, like stick to your chair, hot.',\n",
       "  'tokens': [50588,\n",
       "   865,\n",
       "   11,\n",
       "   300,\n",
       "   390,\n",
       "   294,\n",
       "   264,\n",
       "   4266,\n",
       "   570,\n",
       "   286,\n",
       "   1604,\n",
       "   309,\n",
       "   390,\n",
       "   2368,\n",
       "   11,\n",
       "   411,\n",
       "   957,\n",
       "   2368,\n",
       "   11,\n",
       "   411,\n",
       "   2897,\n",
       "   281,\n",
       "   428,\n",
       "   6090,\n",
       "   11,\n",
       "   2368,\n",
       "   13,\n",
       "   50844],\n",
       "  'temperature': 0.0,\n",
       "  'avg_logprob': -0.3059328445280441,\n",
       "  'compression_ratio': 1.5466101694915255,\n",
       "  'no_speech_prob': 0.04611587896943092},\n",
       " {'id': 2,\n",
       "  'seek': 0,\n",
       "  'start': 10.0,\n",
       "  'end': 12.24,\n",
       "  'text': ' And Fio, you ran him from the backyard, right?',\n",
       "  'tokens': [50864,\n",
       "   400,\n",
       "   479,\n",
       "   1004,\n",
       "   11,\n",
       "   291,\n",
       "   5872,\n",
       "   796,\n",
       "   490,\n",
       "   264,\n",
       "   20036,\n",
       "   11,\n",
       "   558,\n",
       "   30,\n",
       "   50976],\n",
       "  'temperature': 0.0,\n",
       "  'avg_logprob': -0.3059328445280441,\n",
       "  'compression_ratio': 1.5466101694915255,\n",
       "  'no_speech_prob': 0.04611587896943092},\n",
       " {'id': 3,\n",
       "  'seek': 0,\n",
       "  'start': 12.72,\n",
       "  'end': 19.68,\n",
       "  'text': \" You had their muddy boots and mama yelled, not in my kitchen, boy, but you didn't even hear her because you saw him on the floor.\",\n",
       "  'tokens': [51000,\n",
       "   509,\n",
       "   632,\n",
       "   641,\n",
       "   38540,\n",
       "   15194,\n",
       "   293,\n",
       "   18775,\n",
       "   38023,\n",
       "   11,\n",
       "   406,\n",
       "   294,\n",
       "   452,\n",
       "   6525,\n",
       "   11,\n",
       "   3237,\n",
       "   11,\n",
       "   457,\n",
       "   291,\n",
       "   994,\n",
       "   380,\n",
       "   754,\n",
       "   1568,\n",
       "   720,\n",
       "   570,\n",
       "   291,\n",
       "   1866,\n",
       "   796,\n",
       "   322,\n",
       "   264,\n",
       "   4123,\n",
       "   13,\n",
       "   51348],\n",
       "  'temperature': 0.0,\n",
       "  'avg_logprob': -0.3059328445280441,\n",
       "  'compression_ratio': 1.5466101694915255,\n",
       "  'no_speech_prob': 0.04611587896943092}]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = whisper.load_model(\"base\")\n",
    "\n",
    "results = model.transcribe(audio)\n",
    "results[\"segments\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the speaker based on the diarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPEAKER_00\n",
      "SPEAKER_01\n",
      "SPEAKER_01\n",
      "SPEAKER_01\n"
     ]
    }
   ],
   "source": [
    "def assign_speakers(diarization_segments: dict, transcript_segments: dict):\n",
    "    diarization_list = []\n",
    "    for speaker, segs in diarization_segments.items():\n",
    "        for seg in segs:\n",
    "            diarization_list.append({'speaker': speaker, 'start': seg.start, 'end': seg.end})\n",
    "\n",
    "\n",
    "    for ts in transcript_segments:\n",
    "        mid = (ts[\"start\"] + ts[\"end\"]) / 2\n",
    "        # find the speaker that is closest to the midpoint\n",
    "        speaker = None\n",
    "\n",
    "        for seg in diarization_list:\n",
    "            if seg[\"start\"] <= mid <= seg[\"end\"]:\n",
    "                speaker = seg[\"speaker\"]\n",
    "                print(speaker)\n",
    "                break\n",
    "\n",
    "assign_speakers(diar_segments, results[\"segments\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
